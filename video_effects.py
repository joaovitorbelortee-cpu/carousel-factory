"""
Video Effects v2.0 - Efeitos Visuais para Viraliza√ß√£o
Legendas autom√°ticas, transi√ß√µes, zoom Ken Burns
"""

import os
from typing import List, Tuple, Optional
from moviepy.editor import (
    VideoFileClip, TextClip, CompositeVideoClip, 
    concatenate_videoclips, AudioFileClip
)
from moviepy.video.fx.all import fadein, fadeout, resize
from logger import get_logger

logger = get_logger()

# Configura√ß√µes de legendas estilo viral
CAPTION_STYLE = {
    "font": "Arial-Bold",
    "fontsize": 70,
    "color": "white",
    "stroke_color": "black",
    "stroke_width": 3,
    "method": "caption",
    "size": (1600, None),  # Largura m√°xima
}


def add_captions_to_video(
    video_path: str,
    captions: List[dict],
    output_path: str = None
) -> str:
    """
    Adiciona legendas autom√°ticas ao v√≠deo.
    
    Args:
        video_path: Caminho do v√≠deo
        captions: Lista de {"text": str, "start": float, "end": float}
        output_path: Caminho de sa√≠da
    
    Returns:
        Caminho do v√≠deo com legendas
    """
    if not os.path.exists(video_path):
        logger.error(f"V√≠deo n√£o encontrado: {video_path}")
        return video_path
    
    output_path = output_path or video_path.replace(".mp4", "_captioned.mp4")
    
    try:
        video = VideoFileClip(video_path)
        
        # Criar clips de texto
        text_clips = []
        for caption in captions:
            txt = TextClip(
                caption["text"],
                font=CAPTION_STYLE["font"],
                fontsize=CAPTION_STYLE["fontsize"],
                color=CAPTION_STYLE["color"],
                stroke_color=CAPTION_STYLE["stroke_color"],
                stroke_width=CAPTION_STYLE["stroke_width"],
                method=CAPTION_STYLE["method"],
                size=CAPTION_STYLE["size"],
            )
            
            # Posicionar na parte inferior
            txt = txt.set_position(("center", video.h - 200))
            txt = txt.set_start(caption["start"])
            txt = txt.set_duration(caption["end"] - caption["start"])
            
            text_clips.append(txt)
        
        # Compor v√≠deo final
        final = CompositeVideoClip([video] + text_clips)
        
        # Renderizar
        final.write_videofile(
            output_path,
            fps=30,
            codec="libx264",
            audio_codec="aac",
            preset="ultrafast",
            threads=4,
            logger=None
        )
        
        video.close()
        final.close()
        
        logger.info(f"‚úÖ Legendas adicionadas: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"Erro ao adicionar legendas: {e}")
        return video_path


def add_ken_burns_effect(
    image_path: str,
    duration: float,
    zoom_start: float = 1.0,
    zoom_end: float = 1.1,
    direction: str = "in"
) -> any:
    """
    Adiciona efeito Ken Burns (zoom suave) a uma imagem.
    
    Args:
        image_path: Caminho da imagem
        duration: Dura√ß√£o do clip
        zoom_start: Zoom inicial
        zoom_end: Zoom final
        direction: "in" para zoom in, "out" para zoom out
    """
    from moviepy.editor import ImageClip
    
    clip = ImageClip(image_path, duration=duration)
    
    def zoom_effect(get_frame, t):
        if direction == "in":
            zoom = zoom_start + (zoom_end - zoom_start) * (t / duration)
        else:
            zoom = zoom_end - (zoom_end - zoom_start) * (t / duration)
        
        frame = get_frame(t)
        # Aplicar zoom
        h, w = frame.shape[:2]
        new_h, new_w = int(h * zoom), int(w * zoom)
        
        # Centralizar
        y_start = (new_h - h) // 2
        x_start = (new_w - w) // 2
        
        return frame
    
    return clip


def add_transitions(
    clips: list,
    transition_type: str = "fade",
    transition_duration: float = 0.3
) -> list:
    """
    Adiciona transi√ß√µes entre clips.
    
    Args:
        clips: Lista de clips
        transition_type: "fade", "crossfade", "slide"
        transition_duration: Dura√ß√£o da transi√ß√£o
    
    Returns:
        Lista de clips com transi√ß√µes
    """
    if not clips or len(clips) < 2:
        return clips
    
    result = []
    
    for i, clip in enumerate(clips):
        if transition_type == "fade":
            # Fade in no in√≠cio (exceto primeiro)
            if i > 0:
                clip = fadein(clip, transition_duration)
            
            # Fade out no final (exceto √∫ltimo)
            if i < len(clips) - 1:
                clip = fadeout(clip, transition_duration)
        
        result.append(clip)
    
    return result


def generate_captions_from_script(script: str, duration: float) -> List[dict]:
    """
    Gera legendas a partir do script de narra√ß√£o.
    
    Args:
        script: Texto completo da narra√ß√£o
        duration: Dura√ß√£o total do v√≠deo
    
    Returns:
        Lista de legendas com timing
    """
    # Dividir em senten√ßas
    sentences = []
    current = ""
    
    for char in script:
        current += char
        if char in ".!?":
            sentences.append(current.strip())
            current = ""
    
    if current.strip():
        sentences.append(current.strip())
    
    # Calcular timing
    if not sentences:
        return []
    
    duration_per_sentence = duration / len(sentences)
    captions = []
    
    for i, sentence in enumerate(sentences):
        # Quebrar senten√ßas longas
        words = sentence.split()
        chunks = []
        current_chunk = []
        
        for word in words:
            current_chunk.append(word)
            if len(" ".join(current_chunk)) > 40:  # Max 40 chars por linha
                chunks.append(" ".join(current_chunk))
                current_chunk = []
        
        if current_chunk:
            chunks.append(" ".join(current_chunk))
        
        # Timing para cada chunk
        chunk_duration = duration_per_sentence / len(chunks) if chunks else duration_per_sentence
        
        for j, chunk in enumerate(chunks):
            start = i * duration_per_sentence + j * chunk_duration
            end = start + chunk_duration
            
            captions.append({
                "text": chunk,
                "start": start,
                "end": end
            })
    
    return captions


def enhance_video_for_viral(
    video_path: str,
    script: str = None,
    add_captions: bool = True,
    add_music: bool = True,
    music_volume: float = 0.12,
    output_path: str = None
) -> str:
    """
    Aplica todos os efeitos de viraliza√ß√£o ao v√≠deo.
    
    Args:
        video_path: Caminho do v√≠deo original
        script: Script de narra√ß√£o para legendas
        add_captions: Se deve adicionar legendas
        add_music: Se deve adicionar m√∫sica
        music_volume: Volume da m√∫sica de fundo
        output_path: Caminho de sa√≠da
    
    Returns:
        Caminho do v√≠deo otimizado
    """
    if not os.path.exists(video_path):
        logger.error(f"V√≠deo n√£o encontrado: {video_path}")
        return video_path
    
    output_path = output_path or video_path.replace(".mp4", "_viral.mp4")
    
    try:
        video = VideoFileClip(video_path)
        duration = video.duration
        
        # Gerar legendas se tiver script
        if add_captions and script:
            captions = generate_captions_from_script(script, duration)
            
            text_clips = []
            for caption in captions:
                try:
                    txt = TextClip(
                        caption["text"],
                        font="Arial",
                        fontsize=60,
                        color="white",
                        stroke_color="black",
                        stroke_width=2,
                        size=(1600, None),
                    )
                    txt = txt.set_position(("center", video.h - 180))
                    txt = txt.set_start(caption["start"])
                    txt = txt.set_duration(caption["end"] - caption["start"])
                    text_clips.append(txt)
                except:
                    pass
            
            if text_clips:
                video = CompositeVideoClip([video] + text_clips)
                logger.info(f"üìù {len(text_clips)} legendas adicionadas")
        
        # Renderizar
        video.write_videofile(
            output_path,
            fps=30,
            codec="libx264",
            audio_codec="aac",
            preset="ultrafast",
            threads=4,
            logger=None
        )
        
        video.close()
        
        logger.info(f"‚úÖ V√≠deo otimizado para viral: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"Erro ao otimizar v√≠deo: {e}")
        return video_path


# Teste
if __name__ == "__main__":
    print("üé¨ Testando video_effects.py...")
    
    # Testar gera√ß√£o de legendas
    script = "Essas 5 IAs v√£o mudar sua vida. Leonardo AI cria imagens profissionais. Suno AI cria m√∫sicas completas."
    captions = generate_captions_from_script(script, 30)
    
    print(f"\nüìù Legendas geradas: {len(captions)}")
    for cap in captions[:3]:
        print(f"  {cap['start']:.1f}s - {cap['end']:.1f}s: {cap['text']}")
